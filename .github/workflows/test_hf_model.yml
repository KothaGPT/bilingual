name: Test Hugging Face Model

on:
  workflow_dispatch:
    inputs:
      repo_id:
        description: 'Hugging Face repository ID (username/model-name)'
        required: true
        type: string
  schedule:
    # Run weekly on Monday at 00:00 UTC
    - cron: '0 0 * * 1'

jobs:
  test-model:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install transformers torch pytest
      
      - name: Test model loading
        env:
          REPO_ID: ${{ inputs.repo_id || 'your-username/bn-wikipedia-lm' }}
        run: |
          python -c "
          from transformers import AutoTokenizer, AutoModelForMaskedLM
          import sys
          
          try:
              print(f'Testing model: $REPO_ID')
              tokenizer = AutoTokenizer.from_pretrained('$REPO_ID')
              model = AutoModelForMaskedLM.from_pretrained('$REPO_ID')
              print('✓ Model loaded successfully')
              sys.exit(0)
          except Exception as e:
              print(f'✗ Model loading failed: {e}')
              sys.exit(1)
          "
      
      - name: Test inference
        env:
          REPO_ID: ${{ inputs.repo_id || 'your-username/bn-wikipedia-lm' }}
        run: |
          python -c "
          from transformers import AutoTokenizer, AutoModelForMaskedLM, pipeline
          import sys
          
          try:
              print('Testing inference...')
              tokenizer = AutoTokenizer.from_pretrained('$REPO_ID')
              model = AutoModelForMaskedLM.from_pretrained('$REPO_ID')
              
              fill_mask = pipeline('fill-mask', model=model, tokenizer=tokenizer, device=-1)
              results = fill_mask('বাংলাদেশের রাজধানী [MASK]', top_k=3)
              
              print('Predictions:')
              for i, result in enumerate(results, 1):
                  print(f'  {i}. {result[\"sequence\"]} (score: {result[\"score\"]:.4f})')
              
              print('✓ Inference test passed')
              sys.exit(0)
          except Exception as e:
              print(f'✗ Inference test failed: {e}')
              sys.exit(1)
          "
      
      - name: Run comprehensive tests
        env:
          REPO_ID: ${{ inputs.repo_id || 'your-username/bn-wikipedia-lm' }}
        run: |
          python scripts/huggingface/test_hf_model.py --repo $REPO_ID
      
      - name: Report results
        if: always()
        run: |
          echo "Test completed for Python ${{ matrix.python-version }}"
