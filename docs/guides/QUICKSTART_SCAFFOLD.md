# Quick Start: Scaffold Implementation

This guide helps you get started with the newly implemented scaffold structure.

## ğŸš€ What Was Implemented

The complete scaffold structure for literary and semantic modules, including:

- **8 new module files** with stub implementations
- **5 training/evaluation scripts** ready for implementation
- **3 new test files** with comprehensive test cases
- **1 CI/CD workflow** for automated testing
- **Updated module exports** for easy imports

## ğŸ“ Directory Structure

```
bilingual/
â”œâ”€â”€ datasets/
â”‚   â”œâ”€â”€ literary/          # Curated poetry, novels
â”‚   â”œâ”€â”€ semantic/          # Wikipedia or bilingual corpora (NEW)
â”‚   â””â”€â”€ wikipedia/
â”œâ”€â”€ src/bilingual/modules/
â”‚   â”œâ”€â”€ literary_lm.py              # NEW: Literary LM
â”‚   â”œâ”€â”€ style_transfer_gpt.py       # NEW: GPT-based style transfer
â”‚   â”œâ”€â”€ metaphor_simile_detector.py # NEW: Figurative language
â”‚   â”œâ”€â”€ sentiment_tone_classifier.py # NEW: Sentiment analysis
â”‚   â”œâ”€â”€ cross_lingual_embed.py      # NEW: Cross-lingual embeddings
â”‚   â”œâ”€â”€ named_entity_recognizer.py  # NEW: NER for Bangla
â”‚   â””â”€â”€ text_complexity_predictor.py # NEW: Readability analysis
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_literary_lm.py        # NEW
â”‚   â”œâ”€â”€ evaluate_literary.py        # NEW
â”‚   â”œâ”€â”€ train_style_transfer.py     # NEW
â”‚   â”œâ”€â”€ evaluate_semantic.py        # NEW
â”‚   â””â”€â”€ preprocess_literary.py      # NEW
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ literary/
â”‚   â”‚   â””â”€â”€ test_style_transfer_gpt.py  # NEW
â”‚   â””â”€â”€ semantic/
â”‚       â”œâ”€â”€ test_cross_lingual_embed.py # NEW
â”‚       â””â”€â”€ test_text_complexity.py     # NEW
â””â”€â”€ .github/workflows/
    â””â”€â”€ test_models.yml             # NEW: CI workflow
```

## ğŸ”§ Setup

### 1. Install Dependencies

```bash
# Install all requirements
pip install -r requirements.txt

# Or install minimal dependencies for testing
pip install pytest pytest-cov
```

### 2. Verify Installation

```bash
# Check if tests can be discovered
pytest tests/literary tests/semantic --collect-only

# Run a simple import test (requires torch)
python3 -c "from bilingual.modules import LiteraryLM; print('Success!')"
```

## ğŸ“ Usage Examples

### Literary LM

```python
from bilingual.modules import LiteraryLM

# Initialize and load model
lm = LiteraryLM("models/bilingual-lm")
lm.load_model()

# Generate literary text
text = lm.generate_text("à¦¬à¦¾à¦‚à¦²à¦¾ à¦•à¦¬à¦¿à¦¤à¦¾", max_length=100)
print(text)
```

### Style Transfer

```python
from bilingual.modules import StyleTransferGPT

# Initialize model
model = StyleTransferGPT("models/style-transfer")
model.load_model()

# Convert to different styles
formal = model.convert("à¦†à¦®à¦¿ à¦­à¦¾à¦¤ à¦–à¦¾à¦‡", "formal")
poetic = model.convert("à¦šà¦¾à¦à¦¦ à¦‰à¦ à§‡à¦›à§‡", "poetic")
```

### Cross-lingual Embeddings

```python
from bilingual.modules import embed_text, compute_similarity

# Generate embeddings
emb_bn = embed_text("à¦†à¦®à¦¿ à¦­à¦¾à¦¤ à¦–à¦¾à¦‡", lang="bn")
emb_en = embed_text("I eat rice", lang="en")

# Compute similarity
similarity = compute_similarity(
    "à¦†à¦®à¦¿ à¦­à¦¾à¦¤ à¦–à¦¾à¦‡",
    "I eat rice",
    lang1="bn",
    lang2="en"
)
```

### Named Entity Recognition

```python
from bilingual.modules import extract_entities, extract_entities_by_type

# Extract all entities
entities = extract_entities("à¦°à¦¬à§€à¦¨à§à¦¦à§à¦°à¦¨à¦¾à¦¥ à¦•à¦²à¦•à¦¾à¦¤à¦¾à¦¯à¦¼ à¦¥à¦¾à¦•à¦¤à§‡à¦¨")

# Extract specific types
persons = extract_entities_by_type(text, "PERSON")
locations = extract_entities_by_type(text, "LOCATION")
```

### Text Complexity

```python
from bilingual.modules import predict_complexity, classify_difficulty

# Predict complexity score
score = predict_complexity("à¦¬à¦¾à¦‚à¦²à¦¾ à¦¸à¦¾à¦¹à¦¿à¦¤à§à¦¯à§‡à¦° à¦‡à¦¤à¦¿à¦¹à¦¾à¦¸")

# Classify difficulty level
level = classify_difficulty(text)  # beginner/intermediate/advanced/expert
```

## ğŸ§ª Running Tests

### Run All Tests

```bash
# Run all literary and semantic tests
pytest tests/literary tests/semantic -v

# With coverage report
pytest tests/literary tests/semantic -v --cov=src/bilingual --cov-report=term
```

### Run Specific Tests

```bash
# Test literary LM
pytest tests/literary/test_literary_lm.py -v

# Test style transfer
pytest tests/literary/test_style_transfer_gpt.py -v

# Test cross-lingual embeddings
pytest tests/semantic/test_cross_lingual_embed.py -v

# Test text complexity
pytest tests/semantic/test_text_complexity.py -v
```

## ğŸ”¨ Training Scripts

### Train Literary LM

```bash
python scripts/train_literary_lm.py \
    --dataset_path datasets/literary/corpus.txt \
    --model_path models/bilingual-lm \
    --epochs 3 \
    --batch_size 8
```

### Train Style Transfer

```bash
python scripts/train_style_transfer.py \
    --dataset_path datasets/literary/style_pairs.json \
    --model_path models/style-transfer-gpt \
    --source_style formal \
    --target_style informal
```

### Preprocess Data

```bash
python scripts/preprocess_literary.py \
    --input_path datasets/literary/raw/ \
    --output_path datasets/literary/processed/ \
    --clean
```

## ğŸ“Š Evaluation Scripts

### Evaluate Literary Models

```bash
python scripts/evaluate_literary.py \
    --model_path models/bilingual-lm \
    --test_dataset datasets/literary/test.json \
    --output_path results/literary_eval.json
```

### Evaluate Semantic Models

```bash
python scripts/evaluate_semantic.py \
    --test_dataset datasets/semantic/test.json \
    --output_path results/semantic_eval.json
```

## ğŸ”„ CI/CD Workflow

The CI workflow (`.github/workflows/test_models.yml`) automatically:

1. Tests on Python 3.10 and 3.11
2. Runs literary tests
3. Runs semantic tests
4. Generates coverage reports
5. Uploads to Codecov
6. Archives HTML coverage reports

Triggered on:
- Push to `main` or `develop` branches
- Pull requests to `main` or `develop`

## ğŸ“‹ Next Steps

### Immediate (PR-2)
1. Implement `LiteraryLM.load_model()` with actual transformers model
2. Implement `LiteraryLM.generate_text()` with proper generation
3. Connect with training script
4. Add integration tests

### Short-term (PR-3 & PR-4)
1. Implement style transfer with GPT
2. Implement metaphor/simile detection
3. Implement sentiment classification
4. Train initial models

### Medium-term (PR-5 & PR-6)
1. Implement cross-lingual embeddings
2. Implement NER
3. Implement complexity prediction
4. Curate datasets

### Long-term (PR-7 & PR-8)
1. Complete training/evaluation scripts
2. Benchmark models
3. Prepare for Hugging Face Hub
4. Deploy demos

## ğŸ“š Documentation

- **[Implementation Summary](SCAFFOLD_IMPLEMENTATION.md)** - Detailed implementation notes
- **[Module Reference](docs/MODULE_REFERENCE.md)** - API documentation
- **[Wikipedia Workflow](docs/WIKIPEDIA_WORKFLOW.md)** - Existing workflow docs

## âš ï¸ Important Notes

1. **Stub Implementations**: All modules currently have placeholder implementations with TODO markers
2. **Dependencies**: Requires torch, transformers, and other ML libraries (see requirements.txt)
3. **Testing**: Tests verify structure and types, not actual functionality yet
4. **Incremental Development**: Follow the PR plan for systematic implementation

## ğŸ¤ Contributing

When implementing actual functionality:

1. Keep the existing function signatures
2. Update TODO markers as you implement
3. Add proper error handling
4. Update tests with real assertions
5. Add integration tests
6. Update documentation

## ğŸ“ Support

For questions or issues:
- Check the [Implementation Summary](SCAFFOLD_IMPLEMENTATION.md)
- Review the [Module Reference](docs/MODULE_REFERENCE.md)
- Look at existing implementations in `src/bilingual/modules/`

---

**Status**: âœ… Scaffold Complete - Ready for Implementation

**Last Updated**: October 23, 2025
