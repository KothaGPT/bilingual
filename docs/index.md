# Home

# ğŸŒ **Bilingual NLP Toolkit**

*A next-generation bilingual Banglaâ€“English NLP ecosystem for advanced text processing, translation, and generation.*

[![PyPI version](https://badge.fury.io/py/bilingual.svg)](https://badge.fury.io/py/bilingual)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

The **Bilingual NLP Toolkit** is a comprehensive, production-ready Python package that provides high-quality Bangla and English support for natural language processing tasks. Built for the modern AI era, it combines cutting-edge transformer models with robust data processing pipelines.

## âœ¨ Key Features

### ğŸš€ **Advanced Text Processing**
- **Automatic Language Detection**: Seamlessly identify Bangla and English content
- **Mixed-Language Support**: Process text with code-switching and bilingual content
- **Data Augmentation**: Generate diverse training data with paraphrasing and noise injection
- **Text Normalization**: Clean and standardize multilingual text

### ğŸ¤– **State-of-the-Art Models**
- **Transformer Integration**: T5, BART, mT5, and mBART models for generation and translation
- **Multilingual Fine-Tuning**: Optimized for Bangla-English parity
- **Zero-Shot Learning**: Cross-lingual understanding without task-specific training
- **ONNX Deployment**: Lightweight models for production environments

### ğŸ“Š **Comprehensive Evaluation**
- **BLEU/ROUGE/METEOR**: Industry-standard translation metrics
- **Diversity Metrics**: Measure generation quality and variety
- **Human-in-the-Loop**: Interactive content safety evaluation
- **Cross-Language Consistency**: Ensure parity between Bangla and English

### ğŸ›¡ï¸ **Production Ready**
- **Type Safety**: Full type annotations for better IDE support
- **Error Handling**: Robust exception management and fallbacks
- **Configuration Management**: Environment-based settings with validation
- **Testing Suite**: Comprehensive unit, integration, and fuzz testing

## ğŸš€ Quick Start

### Installation

```bash
pip install bilingual
```

### Basic Usage

```python
import bilingual as bb

# Language Detection
text = "à¦†à¦®à¦¿ à¦¸à§à¦•à§à¦²à§‡ à¦¯à¦¾à¦‡ à¦à¦¬à¦‚ à¦¬à¦‡ à¦ªà¦¡à¦¼à¦¤à§‡ à¦­à¦¾à¦²à§‹à¦¬à¦¾à¦¸à¦¿à¥¤"
result = bb.detect_language(text)
print(f"Language: {result['language']}")  # Output: bengali

# Text Processing Pipeline
processed = bb.process(text, tasks=["normalize", "tokenize", "augment"])
print(processed)

# Translation
translated = bb.translate_text("t5-small", "Hello world", "en", "bn")
print(translated)

# Evaluation
references = ["I love reading books"]
candidates = ["I adore reading books"]
score = bb.evaluate_translation(references, candidates)
print(f"BLEU Score: {score['bleu']:.4f}")
```

## ğŸŒ **Bilingual Excellence**

The toolkit is specifically designed for Bangla-English bilingual processing:

- **Cultural Sensitivity**: Content validation for child-appropriate material
- **Language Parity**: Equal performance across both languages
- **Code-Switching Support**: Handle mixed-language content naturally
- **Educational Focus**: Optimized for learning and teaching applications

## ğŸ—ï¸ **Architecture**

```
bilingual/
â”œâ”€â”€ language_detection.py     # Automatic language identification
â”œâ”€â”€ data_augmentation.py      # Text augmentation techniques
â”œâ”€â”€ multi_input.py           # Mixed-language processing
â”œâ”€â”€ evaluation.py            # Comprehensive metrics
â”œâ”€â”€ transformer_models.py    # Model integration & inference
â”œâ”€â”€ onnx_converter.py        # Production deployment
â”œâ”€â”€ human_evaluation.py      # Safety & content validation
â”œâ”€â”€ config.py               # Configuration management
â”œâ”€â”€ testing.py              # Test suite & benchmarks
â””â”€â”€ cli.py                  # Command-line interface
```

## ğŸ¤ **Contributing**

We welcome contributions from the community! See our [Contributing Guide](contributing/index.md) for details on:

- Development setup and guidelines
- Data contribution and annotation
- Model training and evaluation
- Documentation improvements

## ğŸ“„ **License**

Licensed under the Apache License 2.0. See [LICENSE](license.md) for details.

## ğŸ™ **Acknowledgments**

Built with â¤ï¸ for the bilingual AI community. Special thanks to:

- The Hugging Face team for transformers and datasets
- The PyTorch team for the ML framework
- The open-source NLP community for inspiration and tools
